---
layout:     post
title:      Nginx学习笔记
subtitle:   ......
date:       2022-5-5
author:     呆贝斯
header-img: img/post-bg-desk.jpg
onTop: true
catalog: true
tags:
    - Nginx
---
# Nginx基本概念
1. Nginx是什么，做什么事情？

      nginx是一个高性能的HTTP和反向代理服务器，特点是占有内存少，并发能力强。
    nginx可以作为静态页面的web服务器，同时还支持CGI协议的动态语言，比如perl、php等。
    但是不支持java。java程序只能通过tomcat配合完成。
    nginx专为性能优化而开发，性能是其最重要的考量，实现上非常注重效率，能经受高负载的经验，
    有报告表明能支持高达50000个并发连接数。

2. `正向代理`

      在客户端（浏览器）配置代理服务器，通过代理服务器进行互联网访问。
    ![](/img/forward_proxy.png)

3. `反向代理`

      反向代理，其实客户端对代理是无感知的，因为客户端不需要任何配置就可以访问，
    我们只需要将请求发送到反向代理服务器，由反向代理服务器去选择目标服务器获取数据后，
    再返回给客户端，此时反向代理服务器和目标服务器对外就是一个服务器，暴露的是代理服务器的地址，
    隐藏了真实服务器IP地址。
    ![](/img/reverse_proxy.png)

4. `负载均衡`

      单个服务器解决不了，我们增加服务器的数量，然后将请求分发到各个服务器上，
    将原先请求集中到单个服务器上的情况改为将请求分发到多个服务器上，将负载分发到不同的服务器，
    也就是我们所说的负载均衡。
    ![](/img/load_balancing.png)

5. `动静分离`

      为了加快网站的解析速度，可以把动态页面和静态页面由不同的服务器来解析，
    加快解析速度。降低原来单个服务器的压力。
    ![](/img/dynamic_static_separation.png)

# Nginx的原理解析
+ 原理图
![](/img/nginx_principle.png)
+ worker是总样工作的？
![](/img/nginx_worker.png)
+ worker是总样工作的？
    1. 可以使用nginx -s reload热部署，利于nginx进行热部署操作
    2. 每个worker是独立的进程，如果有一个worker出现问题，其他worker是独立的，继续进行争抢，实现请求过程，不会造成服务中断。
+ 设置多少个worker合适？

      nginx同redis类似都采用io多路复用机制，每个worker都是一个独立的进程，
    但每个进程里只有一个主线程，通过异步非阻塞方式来处理请求，即使是成千上万个请求也不在话下，
    每个worker的线程可以把一个cpu的性能发挥到极致.所以worker数和服务器的cpu数相等是最为适宜。
    设少了会浪费cpu，设多了会造成cpu平凡切换上下文带来损耗。
+ 发送请求，占用了worker的几个连接数(worker connection)？

    两个或者四个（看应用场景）

+ nginx有一个master，有四个worker，每个worker支持最大的连接数是1024，支持的并发数是多少个？
    + 普通的静态访问最大并发数：worker_connection*worker_process/2
    + 作为反向代理来说，最大支持并发数量应该是：worker_connection*worker_process/4


# nginx安装、常用命令和配置文件
1. Linux系统安装Nginx
    + 普通安装
    + Docker安装
2. Nginx常用命令
    + 使用nginx操作命令前提条件，必须进入nginx的目录。/usr/local/nginx/sbin 
    + 查看nginx的版本号  ./nginx -v 
    + 启动nginx  ./nginx 
    + 关闭nginx  ./nginx -s stop 
    + 重新加载nginx  ./nginx -s reload
3. Nginx配置文件
    1. nginx配置文件的位置

        /usr/local/nginx/conf/nginx.conf

    2. nginx配置文件的组成
        1. `全局块`

              从配置文件开始到events块之间的内容，
            主要会设置一些影响nginx服务器整体运行的配置指令，
            主要包括配置运行nginx服务器的用户（组）、允许生成的work process数，
            进程PID存放路径、日志存放路径和类型以及配置文件的引入等。
            例如worker processes 1；worker_processes值越大，可以支持的并发处理量也越多。

        2. `events块`

              events块涉及的指令主要影响nginx服务器与用户的网络连接，
            常用的设置包括是否开启对多work process下的网络连接进行序列化，
            是否允许同时接收多个网络连接，选取哪种事件驱动模型来处理连接请求，
            每个word process可以同时支持的最大连接数等。
            ```
            events {
                worker_connections  1024;
            }
            ``` 
              上述例子就表示每个work process支持的最大连接数为1024。
            这部分的配置对nginx的性能影响较大，在实际中应该灵活配置。

        3. `http块`

              这块是nginx服务器中配置最频繁的部分，代理、缓存和日志定义等绝大多数功能和第三方模块的配置都在这里。
            需要注意的是，http块也可以包括http全局块、server块。

              http全局块，http全局块配置的指令包括文件引入、MIMIE-TYPE定义、连接超时时间、单链接请求数上限等。

              server块，这块和虚拟主机有密切关系，虚拟主机从用户角度看，和一台独立的硬件主机是完全一样的，
            该技术的产生是为了节省互联网服务器的硬件成本。每个http块可以包括多个server块，而每个server块就相当于一个虚拟主机。
            而每个server块也分为全局server块，以及可以同时包含多个location块。

# Nginx配置示例
1. `反向代理`
    + 实现效果

        打开浏览器，在浏览器地址栏输入网址 www.bookhub.com.cn ，跳转linux系统中部署的服务主页。
    + 准备工作

        设置www.bookhub.com.cn的解析地址为服务器外网ip，在服务器上启动一个端口例如为8080的服务。对外开放访问80端口
    + 访问过程分析
        ![](/img/nginx_reverse_proxy_process.png)
    + 具体配置
        ```
        server {
            listen 80;
            server_name www.bookhub.com.cn;
            location / {
                proxy_pass http://127.0.0.1:8080;
            }
        }
        ```
    + location指令说明
        该指令用于匹配url，语法如下：
        ```
        # 注意：如果url包含正则表达式，则必须要有~或者~*标识。
        location [ = | ~ | ~* | ^~] url {
        
        }
        ```
        + =：用于不含正则表达式的url前，要求请求字符串与url严格匹配，如果匹配成功，就停止继续向下搜索并立即处理该请求。
        + ~：用于表示url包含正则表达式，并且区分大小写。
        + ~*：用于表示url包含正则表达式，并且不区分大小写。 
        + ^~:用于不包含正则表达式的url前，要求nginx服务器找到标识url和请求字符串匹配度最高的location后，立即使用此location处理请求，而不再用location块中的正则url和请求字符串做匹配。
2. `负载均衡`
    + 实现效果

        浏览器输入地址，实现负载均衡效果。
    + 主备工作

        准备两台服务器。
    + 具体配置

        ```
        http{
            ......
            upstream backend {
                ip_hash;
                server 127.0.0.1:8080 weight=1;
                server 192.168.0.100:8080 weight=1;
            }
            ......
            server{
                ......
                location / {
                    ......
                    proxy_pass http://backend;
                    proxy_connect_timeout 10;
                }
            }
        }
        ```
    + 说明
        随着互联网信息爆炸性增长，负载均衡已经不再是一个很陌生的话题，顾名思义，
        负载均衡即是将负载分摊到不同的服务单元，既保证服务的可用性，又保证响应的足够快，
        给用户很好的体验。在linux下有nginx、LVS、Haproxy等等服务可以提供负载均衡服务，
        而且Nginx提供了几种分配方式：
        + 轮询（默认）

            每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器down掉，能自动剔除。
        + weight
        
            weight代表权重，默认为一，权重越高被分配的客户端越多。
            指定轮询几率，weight和访问率成正比，用于后端服务器性能不均的情况。
            ```
            upstream backend {
                server 127.0.0.1:8080 weight=2;
                server 192.168.0.100:8080 weight=1;
            }
            ```
        + ip_hash

            每个请求按访问ip的hash结果分配，这样每个访客固定访问一个后端服务器，可以解决session的问题。
            ```
            upstream backend {
                ip_hash
                server 127.0.0.1:8080;
                server 192.168.0.100:8080;
            }
            ```
        + fair(第三方)

            按后端服务器的响应时间来分配请求，响应时间短的优先分配。
            ```
            upstream backend {
                server 127.0.0.1:8080;
                server 192.168.0.100:8080;
                fair;
            }
            ```
3. `动静分离`
4. `配置高可用集群`